% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/btm_coherence.R
\name{btm_coherence}
\alias{btm_coherence}
\title{Calculate coherence scores for each topic}
\usage{
btm_coherence(model, DTM, N = 10)
}
\arguments{
\item{model}{topic model of choice}

\item{DTM}{DTM object}

\item{N}{Number of terms}
}
\value{
Average coherence of each topic
}
\description{
From https://github.com/bnosac/BTM/issues/3#issuecomment-742515859; one of the issues of "coherence scores" is that coherence is dominant
in models with smaller number of topics that capture frequent usage of common language, hence Roberts et al in building the STM package propose using a mixture of exclusivity and coherence.
With the BTM option of \code{background = TRUE} which captures the most frequently used common terms, this is potentially less of an issue.
Thus far, the modelsappear to be functioning well with fairly good discrimination across topics.
}
\examples{
\dontrun{
coherence <- purrr::map_dfr(testing_models, btm_coherence, DTM = dtm) |>
    tidyr::gather(key = "Topic", value = "Value")
}
}
